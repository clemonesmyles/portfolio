---
title: Transforming veteran support with AI-powered search
client: Department of Veterans' Affairs (DVA)
summary: Led product strategy and human-centered AI design to help veterans access trusted information using natural language, while maintaining trust and accountability in a high-stakes government environment.
year: "2023"
tags: ["AI", "Government", "Product Strategy", "Human-Centered Design"]
image: /images/projects/dva-digital-transformation/hero.jpg
---

## Overview

The Department of Veterans' Affairs (DVA) supports veterans and their families through some of life's most complex and sensitive moments — navigating health, financial support, entitlements, and long-term care.

While DVA holds a vast amount of trusted information, many veterans struggled to access it in ways that felt clear, relevant, and reassuring. Information was often written in policy-heavy language, spread across multiple pages and pathways, and difficult to interpret without prior knowledge of how the system worked. For people already under emotional or cognitive load, this created uncertainty at exactly the moments clarity mattered most.

DVA recognised the potential for AI to help people access information more naturally — but only if it could be applied in a way that strengthened trust, preserved accuracy, and respected the seriousness of the context.

**My responsibilities:** Product strategy • Human-centred AI (HCD AI) • Product definition • Workshop facilitation • UX writing & design

![DVA information architecture challenge](/images/projects/dva-digital-transformation/overview.jpg)

## Framing the opportunity

This was not a traditional search or navigation problem.

The real challenge was confidence: helping veterans feel assured they were reading the right information, from a trusted source, and knowing what to do next. In a government environment, speed alone is not a success metric — an answer that is fast but incorrect, outdated, or poorly framed can cause real harm.

Rather than starting with technology, the work focused on understanding where people became stuck, which questions surfaced repeatedly, and where existing experiences failed under real-world conditions. AI was treated as a potential enabler, not a solution in itself, and only explored where it could meaningfully reduce confusion without introducing new risk.

> "The real challenge was confidence: helping veterans feel assured they were reading the right information, from a trusted source, and knowing what to do next."

![User research insights](/images/projects/dva-digital-transformation/research.jpg)

## Approach

I led product strategy and experience design across discovery and delivery, working closely with DVA stakeholders across digital, policy, and service teams. From early on, engineers were deeply embedded in the work, shaping decisions around feasibility, system behaviour, and operational constraints alongside experience and strategy considerations.

A central principle was restraint. The AI was never positioned as a new source of truth or an open-ended conversational agent. Instead, it was designed as a layer that helps people interpret and navigate existing, approved DVA content, using natural language while remaining grounded in verified sources.

Clear boundaries were defined around what the system could and could not do. Equal weight was given to what happens when confidence is high and when it is not — ensuring the experience could defer, escalate, or guide users to human support rather than overstepping its role.

![Design process and collaboration](/images/projects/dva-digital-transformation/process.jpg)

## The solution

The outcome is a fully developed, live AI-powered search and Q&A experience that supports veterans in finding clear, relevant information using their own words.

Users can ask questions in plain language and receive structured, easy-to-scan responses that draw directly from trusted DVA sources. Answers surface relevant guidance, clearly reference where information comes from, and help users understand next steps — whether that's reading further, accessing a service, or speaking with someone directly.

![AI-powered search interface](/images/projects/dva-digital-transformation/solution-1.jpg)

![User experience flow and interactions](/images/projects/dva-digital-transformation/solution-2.jpg)

Observability is built into both the experience and the system behind it. Responses are explainable and traceable, allowing teams to see what questions are being asked, which sources are used, where confidence thresholds are met, and where the system chooses to step back. This creates a continuous feedback loop between user behaviour, content quality, and service design.

![System observability and trust indicators](/images/projects/dva-digital-transformation/solution-3.jpg)

Rather than aiming for conversational flair, the experience prioritises clarity, accountability, and trust. It is designed to be helpful without being presumptive, and to fail safely when uncertainty is detected.

![Trust and safety features](/images/projects/dva-digital-transformation/solution-4.jpg)

## Impact

This work demonstrates how AI can be applied responsibly in a high-risk, high-trust government environment.

It provides DVA with a live, production-ready example of human-centred AI in practice, aligns digital, policy, and service teams around a shared operating model, and establishes a repeatable pattern for applying AI to other complex information domains.

More broadly, it reframed how AI is discussed internally — shifting the focus from experimentation or novelty to a more grounded question: where does this genuinely help people, and how do we know it's working?

![Impact metrics and outcomes](/images/projects/dva-digital-transformation/impact.jpg)

## Conclusion

This project reflects my approach to AI-enabled product work: strong problem framing, close collaboration with engineering, and a deep respect for the human and organisational systems technology operates within.

It shows how AI can be designed not as a shortcut or spectacle, but as a careful, accountable layer that improves clarity and confidence in moments that matter — particularly in environments where trust is non-negotiable.
